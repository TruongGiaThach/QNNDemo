{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5150a4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.templates import RandomLayers\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0ee7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 30   # Number of optimization epochs\n",
    "n_layers = 1    # Number of random layers\n",
    "n_train = 1000   # Size of the train dataset\n",
    "n_test = 200     # Size of the test dataset\n",
    "\n",
    "SAVE_PATH = \"../_static/demonstration_assets/quanvolution/\"  # Data saving folder\n",
    "os.makedirs(SAVE_PATH, exist_ok=True)\n",
    "PREPROCESS = True           # If False, skip quantum processing and load data from SAVE_PATH\n",
    "np.random.seed(0)           # Seed for NumPy random number generator\n",
    "tf.random.set_seed(0)       # Seed for TensorFlow random number generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4068bc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from torchvision import datasets\n",
    "\n",
    "# Load CIFAR10 dataset\n",
    "cifar_dataset = datasets.CIFAR10(root='./data', train=True, download=True)\n",
    "train_images, train_labels = cifar_dataset.data, np.array(cifar_dataset.targets)\n",
    "\n",
    "cifar_dataset_test = datasets.CIFAR10(root='./data', train=False, download=True)\n",
    "test_images, test_labels = cifar_dataset_test.data, np.array(cifar_dataset_test.targets)\n",
    "\n",
    "\n",
    "# Reduce dataset size\n",
    "train_images = train_images[:n_train]\n",
    "train_labels = train_labels[:n_train]\n",
    "test_images = test_images[:n_test]\n",
    "test_labels = test_labels[:n_test]\n",
    "\n",
    "# Normalize pixel values to [0, 1]\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Add extra dimension for convolution channels\n",
    "train_images = np.expand_dims(train_images, axis=-1)\n",
    "test_images = np.expand_dims(test_images, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d379d6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=4)\n",
    "# Random circuit parameters\n",
    "rand_params = np.random.uniform(high=2 * np.pi, size=(n_layers, 4))\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def circuit(phi):\n",
    "    # Encoding of 4 classical input values\n",
    "    for j in range(4):\n",
    "        qml.RY(np.pi * phi[j], wires=j)\n",
    "\n",
    "    # Random quantum circuit\n",
    "    RandomLayers(rand_params, wires=list(range(4)))\n",
    "\n",
    "    # Measurement producing 4 classical output values\n",
    "    return [qml.expval(qml.PauliZ(j)) for j in range(4)]\n",
    "def quanv(image):\n",
    "    out = np.zeros((16, 16, 12))  # Adjusted for 32x32 input\n",
    "    for j in range(0, 32, 2):\n",
    "        for k in range(0, 32, 2):\n",
    "            for ch in range(3):  # Process each RGB channel\n",
    "                q_results = circuit([\n",
    "                    image[j, k, ch],\n",
    "                    image[j, k + 1, ch],\n",
    "                    image[j + 1, k, ch],\n",
    "                    image[j + 1, k + 1, ch]\n",
    "                ])\n",
    "                for c in range(4):\n",
    "                    out[j // 2, k // 2, ch * 4 + c] = q_results[c]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867854b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PREPROCESS == True:\n",
    "    q_train_images = []\n",
    "    print(\"Quantum pre-processing of train images:\")\n",
    "    for idx, img in enumerate(train_images):\n",
    "        print(\"{}/{}        \".format(idx + 1, n_train), end=\"\\r\")\n",
    "        q_train_images.append(quanv(img))\n",
    "    q_train_images = np.asarray(q_train_images)\n",
    "\n",
    "    q_test_images = []\n",
    "    print(\"\\nQuantum pre-processing of test images:\")\n",
    "    for idx, img in enumerate(test_images):\n",
    "        print(\"{}/{}        \".format(idx + 1, n_test), end=\"\\r\")\n",
    "        q_test_images.append(quanv(img))\n",
    "    q_test_images = np.asarray(q_test_images)\n",
    "\n",
    "    # Save pre-processed images\n",
    "    np.save(SAVE_PATH + \"q_train_images.npy\", q_train_images)\n",
    "    np.save(SAVE_PATH + \"q_test_images.npy\", q_test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9761118",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 4\n",
    "n_channels = 4\n",
    "fig, axes = plt.subplots(1 + n_channels, n_samples, figsize=(10, 10))\n",
    "for k in range(n_samples):\n",
    "    axes[0, 0].set_ylabel(\"Input\")\n",
    "    if k != 0:\n",
    "        axes[0, k].yaxis.set_visible(False)\n",
    "    axes[0, k].imshow(train_images[k, :, :, 0], cmap=\"gray\")\n",
    "\n",
    "    # Plot all output channels\n",
    "    for c in range(n_channels):\n",
    "        axes[c + 1, 0].set_ylabel(\"Output [ch. {}]\".format(c))\n",
    "        if k != 0:\n",
    "            axes[c, k].yaxis.set_visible(False)\n",
    "        axes[c + 1, k].imshow(q_train_images[k, :, :, c], cmap=\"gray\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e250b807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyModel():\n",
    "    \"\"\"Initializes and returns a custom Keras model which is ready to be trained.\"\"\"\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Input(shape=(14, 14, 12)),  # Explicit Input layer for clarity\n",
    "        keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "        keras.layers.MaxPooling2D((2, 2)),\n",
    "        keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        keras.layers.MaxPooling2D((2, 2)),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(64, activation='relu'),\n",
    "        keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9e3a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_model = MyModel()\n",
    "\n",
    "q_history = q_model.fit(\n",
    "    q_train_images,\n",
    "    train_labels,\n",
    "    validation_data=(q_test_images, test_labels),\n",
    "    batch_size=4,\n",
    "    epochs=n_epochs,\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed39db7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  # Import seaborn for styling\n",
    "import numpy as np\n",
    "\n",
    "# Set Seaborn style (modern way)\n",
    "try:\n",
    "    sns.set_style(\"whitegrid\")  # Use a specific Seaborn style\n",
    "except ImportError:\n",
    "    print(\"Seaborn not installed. Falling back to Matplotlib default style.\")\n",
    "    plt.style.use(\"default\")  # Fallback to Matplotlib's default style\n",
    "\n",
    "# Create subplots\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(6, 9))\n",
    "\n",
    "# Check if history objects exist and have required keys\n",
    "try:\n",
    "    # Plot validation accuracy\n",
    "    ax1.plot(q_history.history[\"val_accuracy\"], \"-ob\", label=\"With quantum layer\")\n",
    "    ax1.plot(c_history.history[\"val_accuracy\"], \"-og\", label=\"Without quantum layer\")\n",
    "    ax1.set_ylabel(\"Accuracy\")\n",
    "    ax1.set_ylim([0, 1])\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.legend()\n",
    "\n",
    "    # Plot validation loss\n",
    "    ax2.plot(q_history.history[\"val_loss\"], \"-ob\", label=\"With quantum layer\")\n",
    "    ax2.plot(c_history.history[\"val_loss\"], \"-og\", label=\"Without quantum layer\")\n",
    "    ax2.set_ylabel(\"Loss\")\n",
    "    ax2.set_ylim(top=2.5)\n",
    "    ax2.set_xlabel(\"Epoch\")\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "except (NameError, KeyError) as e:\n",
    "    print(f\"Error: Could not plot data. Ensure q_history and c_history are defined with 'val_accuracy' and 'val_loss' keys. Details: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f481ede",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
